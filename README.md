# Lip-Sync-AI-model

This is an AI model that does lip-syncing of video with the given audio. the pre-trained model from the github repository of Rudrabah was used here.
it was run in a google colab notebook. we may run every cell as it is. before starting to run we need to open the G-drive and create 2 folders named
Wav2lip and Wav2Lip. in the Folder Wav2Lip we upload the pre-trained model which can be downloaded from the repository of Rudrabah. Into the Wav2Lip 
folder we have the input audio named output10.wav and input video named videoplayback.mp4, after running all cells we may find the output in the google colabs
itself. we need to navigate the path as Wav2Lip/results/result_voice.mp4 to find the final lip synced video result_voice.mp4. This navigation can be 
done by clicking the folders icon in the left pane of the google colab.
